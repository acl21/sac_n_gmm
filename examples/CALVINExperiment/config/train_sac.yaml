defaults:
  - calvin_env: default
  - dataset: calvin_ds # use calvin_task when evaluating task demos 
  - dyn_sys: manifold_gmm # clfds or manifold_gmm
  - agent: sac
  - actor: diag_gaussian_actor
  - critic: double_q_critic
  - _self_

  - override hydra/job_logging: colorlog
  - override hydra/hydra_logging: colorlog

seed: 42
log_dir: ${root}/examples/CALVINExperiment/logs
slurm: false

# root: /home/lagandua/projects/refining-skill-sequences
root: E:/Uni-Freiburg/Research/refining-skill-sequences

# Task params
target_tasks: ['open_drawer', 'close_drawer']
task_sequential: true

# Task Demos
# demos_dir: /work/dlclarge1/lagandua-refine-skills/calvin_demos/
demos_dir: ${root}/examples/CALVINExperiment/data

# Task params
task: ${target_tasks} 
state_type: 'pos'
dim: none

# Skill library
skills_dir: ${root}/examples/CALVINExperiment/skills_ds

# Dataset params:
train: true # false to load validation dataset
dt: 0.0666
sampling_dt: ${dt} # 0.0333
goal_centered: false
normalized: false
is_quaternion: false
fixed_ori: [3.14151725, 0.0631318 , 1.39486548]

# Evaluation and DS params
max_steps: 240
# ds_type: 'clfds' 
# ds_type: 'gmm'

# GMM params
gmm_components: 6
plot: false

# RL Agent params
num_train_steps: 1e3
replay_buffer_capacity: ${num_train_steps}
num_seed_steps: 5
eval_frequency: 10
num_eval_episodes: 10
device: cuda
log_frequency: 10
log_save_tb: false
accumulate_steps: 16

# Environment params
render: false
record: true

# WANDB Logging Params
wandb: false

temp: false

hydra:
  run:
    dir: ${log_dir}/sac-runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: ${log_dir}/sac-runs/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.override_dirname}
  job:
    config:
      override_dirname:
        exclude_keys:
          - log_dir